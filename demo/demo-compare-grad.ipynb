{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3292d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Bloqade\n",
    "using Distributions\n",
    "using LegendrePolynomials\n",
    "using PythonCall\n",
    "using LinearAlgebra\n",
    "using Printf\n",
    "\n",
    "include(\"../src/BloqadeControl.jl\")\n",
    "using .BloqadeControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c73229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parametrization of waveforms\n",
    "n_sites = 2\n",
    "basis = \"legendre\"\n",
    "n_basis = 10\n",
    "use_sigmoid_envolope = true\n",
    "tf = 2.0\n",
    "F0 = [(x)->0.,(x)->0.]\n",
    "\n",
    "# Specify training parameters\n",
    "params = ones((2,n_basis))\n",
    "lr = 5e-2\n",
    "w_l2 = 1e-3\n",
    "n_iter = 500\n",
    "method = \"adam\"\n",
    "\n",
    "# Specify parameters of Rydberg atoms\n",
    "distance = 5.95\n",
    "atoms = generate_sites(ChainLattice(), n_sites, scale=distance);\n",
    "local_detuning = [-1, 1]\n",
    "global_detuning = 0.0\n",
    "n_samples = 10\n",
    "\n",
    "# Specify target state\n",
    "target_state = uniform_state(n_sites) ## uniform superposition state\n",
    "J = UniformScaling(1.)\n",
    "tar_op = density_matrix(target_state).state\n",
    "M = J - tar_op;\n",
    "M = GeneralMatrixBlock(M; nlevel=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9c9c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Optimizer([1.0 1.0 … 1.0 1.0; 1.0 1.0 … 1.0 1.0], 0.05, 0.001, 500, \"adam\", [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup optimizer\n",
    "generator = WaveformGenerator(n_sites, basis, n_basis, use_sigmoid_envolope, F0, tf)\n",
    "model = BloqadeModel(atoms, local_detuning, global_detuning, n_samples, M);\n",
    "optim = Optimizer(params, lr, w_l2, n_iter, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd603fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Norm of grad (FDM) = 3.2911\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finite difference method\n",
    "dx = 1e-4 # stepsize\n",
    "grad0 = grad_fdm(model, generator, optim, dx)\n",
    "grad_fdm1 = vec(grad0)\n",
    "n0 = norm(grad0)\n",
    "@sprintf \"Norm of grad (FDM) = %.4f\" n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e655a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No. of samples: 10, norm of grad (diff-analog) = 3.8481, overlap with grad-fdm = 0.9123\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our method\n",
    "optim.params = params\n",
    "update_waveform!(model, generator, optim.params)\n",
    "backward!(model, generator, optim)\n",
    "grad1 = copy(optim.g)\n",
    "grad1 = vec(grad1)\n",
    "n1 = norm(grad1)\n",
    "overlap1 = dot(grad0./n0, grad1./n1)\n",
    "@sprintf \"No. of samples: %i, norm of grad (diff-analog) = %.4f, overlap with grad-fdm = %.4f\" model.n_samples n1 overlap1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ec301f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No. of samples: 1000, norm of grad (diff-analog) = 3.2970, overlap with grad-fdm = 0.9983\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we increase the number of samples\n",
    "model.n_samples = 1000\n",
    "optim.params = params\n",
    "update_waveform!(model, generator, optim.params)\n",
    "backward!(model, generator, optim)\n",
    "grad2 = copy(optim.g)\n",
    "grad2 = vec(grad2)\n",
    "n2 = norm(grad2)\n",
    "overlap2 = dot(grad0./n0, grad2./n2)\n",
    "@sprintf \"No. of samples: %i, norm of grad (diff-analog) = %.4f, overlap with grad-fdm = %.4f\" model.n_samples n2 overlap2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
